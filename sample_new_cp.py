# -*- coding: utf-8 -*-
"""Sample_NEW_CP

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1A_Ziqx1TWHLlmhd8ebyMzxpXEoNQK4in
"""

from google.colab import drive
drive.mount("/content/drive")

!unzip /content/drive/MyDrive/New_Skin_Data_1.zip

# Commented out IPython magic to ensure Python compatibility.
import os
import time
import pathlib
import itertools
from PIL import Image

# import data handling tools
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# import Deep learning Libraries
import tensorflow as tf
import keras
from keras.models import Sequential
from keras.preprocessing.image import ImageDataGenerator
from keras.layers import Conv2D, MaxPooling2D, Flatten,GlobalAveragePooling2D, Dense, Activation, Dropout, BatchNormalization


# %matplotlib inline

np.random.seed(11) # It's my lucky number
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV
from sklearn.metrics import accuracy_score
import itertools


from tensorflow.keras.applications import ResNet50
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

from sklearn.metrics import classification_report

# Ignore Warnings
import warnings
warnings.filterwarnings("ignore")

train_data_dir = '/content/New_Skin_Data_1/Training'
filepaths = []
labels = []

folds = os.listdir(train_data_dir)
for fold in folds:
    foldpath = os.path.join(train_data_dir, fold)
    filelist = os.listdir(foldpath)
    for file in filelist:
        fpath = os.path.join(foldpath, file)

        filepaths.append(fpath)
        labels.append(fold)

# Concatenate data paths with labels into one dataframe
Fseries = pd.Series(filepaths, name= 'filepaths')
Lseries = pd.Series(labels, name='labels')
train_df = pd.concat([Fseries, Lseries], axis= 1)

# Generate data paths with labels
test_data_dir = '/content/New_Skin_Data_1/Testing'
filepaths = []
labels = []

folds = os.listdir(test_data_dir)
for fold in folds:
    foldpath = os.path.join(test_data_dir, fold)
    filelist = os.listdir(foldpath)
    for file in filelist:
        fpath = os.path.join(foldpath, file)

        filepaths.append(fpath)
        labels.append(fold)

# Concatenate data paths with labels into one dataframe
Fseries = pd.Series(filepaths, name= 'filepaths')
Lseries = pd.Series(labels, name='labels')
test_df = pd.concat([Fseries, Lseries], axis= 1)

# crobed image size
batch_size = 16
img_size = (224, 224)
channels = 3
img_shape = (img_size[0], img_size[1], channels)

tr_gen = ImageDataGenerator()
ts_gen = ImageDataGenerator()

train_gen = tr_gen.flow_from_dataframe( train_df, x_col= 'filepaths', y_col= 'labels',
                                       target_size= img_size, class_mode= 'categorical',
                                       color_mode= 'rgb', shuffle= True, batch_size= batch_size)

test_gen = ts_gen.flow_from_dataframe( test_df, x_col= 'filepaths', y_col= 'labels',
                                      target_size= img_size, class_mode= 'categorical',
                                      color_mode= 'rgb', shuffle= False, batch_size= batch_size)

g_dict = train_gen.class_indices  # defines dictionary {'class': index}
classes = list(g_dict.keys())  # defines list of dictionary's keys (classes), class names : string
images, labels = next(train_gen)  # get a batch size samples from the generator

plt.figure(figsize=(20, 20))

for i in range(11):
    plt.subplot(4, 4, i + 1)
    image = images[i] / 255  # scales data to range (0 - 255)
    plt.imshow(image)
    index = np.argmax(labels[i])  # get image index
    if classes[index] == 'Non_Cancer':
        class_name = 'non_cancer'
    elif classes[index] == 'malignant':
        class_name = 'cancer'
    else:
        class_name = classes[index]
    plt.title(class_name, fontsize=12)
    plt.axis('off')
plt.show()



model = Sequential()

# Input Layer
model.add(Conv2D(32,(3,3),activation='relu',input_shape = (224,224,3)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.2))

# Block 1
model.add(Conv2D(64,(3,3),activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.2))
# Block 2
model.add(Conv2D(128,(3,3),activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.2))
# Block 3
model.add(Conv2D(256,(3,3),activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.2))

# Fully Connected layers
model.add(Flatten())
model.add(Dense(512,activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.2))

# Output layer
model.add(Dense(2,activation='sigmoid'))

model.summary()

model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])

history1 = model.fit(train_gen,
                    validation_data = test_gen,
                     batch_size = 64,
                    epochs = 50)

error = pd.DataFrame(history1.history)

plt.figure(figsize=(18,5),dpi=200)
sns.set_style('darkgrid')

plt.subplot(121)
plt.title('Cross Entropy Loss',fontsize=15)
plt.xlabel('Epochs',fontsize=12)
plt.ylabel('Loss',fontsize=12)
plt.plot(error['loss'])
plt.plot(error['val_loss'])

plt.subplot(122)
plt.title('Classification Accuracy',fontsize=15)
plt.xlabel('Epochs',fontsize=12)
plt.ylabel('Accuracy',fontsize=12)
plt.plot(error['accuracy'])
plt.plot(error['val_accuracy'])

plt.show()



# Evaluvate for train generator
loss,acc = model.evaluate(train_gen)

print('The accuracy of the model for training data is:',acc*100)
print('The Loss of the model for training data is:',loss)

error = pd.DataFrame(history1.history)

plt.figure(figsize=(18,5),dpi=200)
sns.set_style('darkgrid')

plt.subplot(121)
plt.title('Cross Entropy Loss',fontsize=15)
plt.xlabel('Epochs',fontsize=12)
plt.ylabel('Loss',fontsize=12)
plt.plot(error['loss'])
plt.plot(error['val_loss'])

plt.subplot(122)
plt.title('Classification Accuracy',fontsize=15)
plt.xlabel('Epochs',fontsize=12)
plt.ylabel('Accuracy',fontsize=12)
plt.plot(error['accuracy'])
plt.plot(error['val_accuracy'])

plt.show()



# prediction
result = model.predict(test_gen)

y_pred = np.argmax(result, axis = 1)

y_true = test_gen.labels

# Evaluvate
loss,acc = model.evaluate(test_gen)

print('The accuracy of the model for testing data is:',acc*100)
print('The Loss of the model for testing data is:',loss)

print(classification_report(y_true, y_pred,target_names=classes))



"""Resnet50

"""

base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(256, activation='relu')(x)
predictions = Dense(2, activation='softmax')(x)
model_resnet = Model(inputs=base_model.input, outputs=predictions)

model_resnet.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])

train_data_dir = '/content/New_Skin_Data_1/Training'
test_data_dir = '/content/New_Skin_Data_1/Testing'
batch_size = 16
img_size = (224, 224)
channels = 3

tr_gen = ImageDataGenerator()
ts_gen = ImageDataGenerator()

train_gen = tr_gen.flow_from_dataframe(train_df, x_col='filepaths', y_col='labels',
                                      target_size=img_size, class_mode='categorical',
                                      color_mode='rgb', shuffle=True, batch_size=batch_size)

test_gen = ts_gen.flow_from_dataframe(test_df, x_col='filepaths', y_col='labels',
                                     target_size=img_size, class_mode='categorical',
                                     color_mode='rgb', shuffle=False, batch_size=batch_size)

history_resnet = model_resnet.fit(train_gen,
                           validation_data=test_gen,
                           batch_size=64,
                           epochs=30)

error_resnet = pd.DataFrame(history_resnet.history)

plt.figure(figsize=(18, 5), dpi=200)
sns.set_style('darkgrid')

plt.subplot(121)
plt.title('Cross Entropy Loss', fontsize=15)
plt.xlabel('Epochs', fontsize=12)
plt.ylabel('Loss', fontsize=12)
plt.plot(error_resnet['loss'])
plt.plot(error_resnet['val_loss'])

plt.subplot(122)
plt.title('Classification Accuracy', fontsize=15)
plt.xlabel('Epochs', fontsize=12)
plt.ylabel('Accuracy', fontsize=12)
plt.plot(error_resnet['accuracy'])
plt.plot(error_resnet['val_accuracy'])

plt.show()



# Prediction
result = model_resnet.predict(test_gen)
y_pred = result.argmax(axis=1)
y_true = test_gen.labels

# Evaluvate
loss,acc = model_resnet.evaluate(test_gen)

print('The accuracy of the model for testing data is:',acc*100)
print('The Loss of the model for testing data is:',loss)

from sklearn.metrics import mean_squared_error

mse = mean_squared_error(y_true, y_pred)
print('The Mean Squared Error (MSE) for the model is:', mse)

# After training your model, save it to a file
model.save('skin_cancer_resnet_model_1.h5')

from tensorflow.keras.models import load_model

# Load the trained model
model = load_model('/content/skin_cancer_resnet_model_1.h5')  # Replace 'your_model_path.h5' with the actual path to your saved model

import random
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Load the test data generator
test_data_dir = '/content/New_Skin_Data_1/Testing'  # Update with your test data path
ts_gen = ImageDataGenerator(rescale=1./255)  # Normalize the test data
test_gen = ts_gen.flow_from_dataframe(test_df, x_col='filepaths', y_col='labels',
                                     target_size=(224, 224), class_mode='categorical',
                                     color_mode='rgb', shuffle=False, batch_size=1)

# Get a random image and its label from the test dataset
random_index = random.randint(0, len(test_gen) - 1)
random_image, random_label = test_gen[random_index]

# Make a prediction on the random image
prediction = model_resnet.predict(random_image)[0]

# Define class labels
class_labels = ['Non_cancer', 'Cancer']

# Get the predicted class and true class
predicted_class = class_labels[np.argmax(prediction)]
true_class = class_labels[np.argmax(random_label)]

# Calculate accuracy
accuracy = 1 if true_class == predicted_class else 0

# Display the random image, the prediction, and the accuracy
plt.imshow(random_image[0])  # No need to divide by 255 as rescaling is done in the generator
plt.title(f'Predicted Class: {predicted_class}\nTrue Class: {true_class}\nAccuracy: {accuracy}')
plt.show()


"""VGG16"""

from keras.applications import VGG16
from keras.layers import GlobalAveragePooling2D, Dense
from keras.models import Model
from keras.optimizers import Adam
from keras.preprocessing.image import ImageDataGenerator

# Load the pre-trained VGG16 model with ImageNet weights (excluding top classification layers)
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Add custom layers on top of the VGG16 base
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(256, activation='relu')(x)
predictions = Dense(2, activation='softmax')(x)

# Create the new model with the custom layers
model = Model(inputs=base_model.input, outputs=predictions)

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])

# Data directories and parameters
train_data_dir = '/content/New_Skin_Data_1/Training'
test_data_dir = '/content/New_Skin_Data_1/Testing'
batch_size = 16
img_size = (224, 224)
channels = 3

# Create data generators
tr_gen = ImageDataGenerator()
ts_gen = ImageDataGenerator()

train_gen = tr_gen.flow_from_dataframe(train_df, x_col='filepaths', y_col='labels',
                                      target_size=img_size, class_mode='categorical',
                                      color_mode='rgb', shuffle=True, batch_size=batch_size)

test_gen = ts_gen.flow_from_dataframe(test_df, x_col='filepaths', y_col='labels',
                                     target_size=img_size, class_mode='categorical',
                                     color_mode='rgb', shuffle=False, batch_size=batch_size)

# Train the model
history_vgg16 = model.fit(train_gen,
                         validation_data=test_gen,
                         batch_size=64,
                         epochs=30)

# Make predictions
result = model.predict(test_gen)
y_pred = result.argmax(axis=1)
y_true = test_gen.labels
# Evaluate
loss, acc = model.evaluate(test_gen)

print('The accuracy of the model for testing data is:', acc * 100)
print('The Loss of the model for testing data is:', loss)

error_vgg16 = pd.DataFrame(history_vgg16.history)

plt.figure(figsize=(18, 5), dpi=200)
sns.set_style('darkgrid')

plt.subplot(121)
plt.title('Cross Entropy Loss', fontsize=15)
plt.xlabel('Epochs', fontsize=12)
plt.ylabel('Loss', fontsize=12)
plt.plot(error_vgg16['loss'])
plt.plot(error_vgg16['val_loss'])

plt.subplot(122)
plt.title('Classification Accuracy', fontsize=15)
plt.xlabel('Epochs', fontsize=12)
plt.ylabel('Accuracy', fontsize=12)
plt.plot(error_vgg16['accuracy'])
plt.plot(error_vgg16['val_accuracy'])

plt.show()

from sklearn.metrics import mean_squared_error

mse = mean_squared_error(y_true, y_pred)
print('The Mean Squared Error (MSE) for the model is:', mse)

